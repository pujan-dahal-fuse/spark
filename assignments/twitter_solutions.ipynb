{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c22372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the tweets by user\n",
    "# Find how many tweets each user has\n",
    "# Find all the persons mentioned on tweets\n",
    "# Count how many times each person is mentioned\n",
    "# Find the 10 most mentioned persons\n",
    "# Find all the hashtags mentioned on a tweet\n",
    "# Count how many times each hashtag is mentioned\n",
    "# Find the 10 most popular Hashtags\n",
    "# Find the top 5 countries which tweet the most"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc60cba",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8362043a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/21 14:14:57 WARN Utils: Your hostname, tars resolves to a loopback address: 127.0.1.1; using 192.168.1.66 instead (on interface wlan0)\n",
      "22/10/21 14:14:57 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/21 14:14:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "            .builder\\\n",
    "            .appName('twitter')\\\n",
    "            .config('spark.driver.extraClassPath', '/usr/lib/jvm/java-19-openjdk/lib/postgresql-42.5.0.jar')\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14f6d1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- place: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      "\n",
      "+-------------+------------------+---------+--------------------+------------------+\n",
      "|      country|                id|    place|                text|              user|\n",
      "+-------------+------------------+---------+--------------------+------------------+\n",
      "|        India|572692378957430785|   Orissa|@always_nidhi @Yo...|   Srkian_nishu :)|\n",
      "|United States|572575240615796737|Manhattan|@OnlyDancers Bell...|TagineDiningGlobal|\n",
      "|United States|572575243883036672|Claremont|1/ \"Without the a...|       Daniel Beer|\n",
      "+-------------+------------------+---------+--------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType\n",
    "\n",
    "\n",
    "spark.read.format('json').load('data/tweets.json').schema\n",
    "\n",
    "manual_schema = StructType([\n",
    "    StructField('country', StringType(), True),\n",
    "    StructField('id', StringType(), True),\n",
    "    StructField('place', StringType(), True),\n",
    "    StructField('text', StringType(), True),\n",
    "    StructField('user', StringType(), True)\n",
    "])\n",
    "\n",
    "twitter_df = spark.read.format('json').schema(manual_schema).load('data/tweets.json')\n",
    "\n",
    "twitter_df.printSchema()\n",
    "twitter_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "440f5339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload twitter_df to csv\n",
    "twitter_df.toPandas().to_csv('output/twitter/tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e523a0",
   "metadata": {},
   "source": [
    "## 1. Find all the tweets by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b3f030a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the user whose tweets to see: Daniel Beer\n",
      "+-------------+------------------+---------+--------------------+-----------+\n",
      "|      country|                id|    place|                text|       user|\n",
      "+-------------+------------------+---------+--------------------+-----------+\n",
      "|United States|572575243883036672|Claremont|1/ \"Without the a...|Daniel Beer|\n",
      "+-------------+------------------+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "user = input('Enter the user whose tweets to see: ')\n",
    "twitter_df.filter(col('user')==user).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c81aec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to csv\n",
    "twitter_df.filter(col('user')==user).toPandas().to_csv('output/twitter/tweets_of_user.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d9228",
   "metadata": {},
   "source": [
    "## 2. Find how many tweets each user has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "152a77ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                user|num_tweets|\n",
      "+--------------------+----------+\n",
      "|       #QuissyUpSoon|       258|\n",
      "|In√®s Mendes Askiip ‚ô•|       185|\n",
      "|           #4Rentinc|       100|\n",
      "|                  MV|        58|\n",
      "|    williampriceking|        46|\n",
      "|‚úå Follow Me MAEJOR ‚úå|        44|\n",
      "|    Phillthy McNasty|        43|\n",
      "|       K.O.H.O.R.T.S|        41|\n",
      "|  #AMNT KINGTAECRAZY|        41|\n",
      "|        Ghafla.co.ke|        36|\n",
      "|        Ully U Music|        35|\n",
      "|            Codeclic|        33|\n",
      "|  TagineDiningGlobal|        30|\n",
      "|           Lord Dash|        30|\n",
      "|      Herri Setiawan|        29|\n",
      "|          Dell Feddi|        29|\n",
      "|   Kidrauhl Forever‚ù§|        25|\n",
      "|     Trendsmap Paris|        23|\n",
      "|      #TurnYaSneakUp|        22|\n",
      "|                Bel |        19|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_tweets_df = twitter_df\\\n",
    "    .groupBy(col('user'))\\\n",
    "    .count()\\\n",
    "    .withColumnRenamed('count', 'num_tweets')\\\n",
    "    .orderBy(col('count').desc())\n",
    "num_tweets_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4145f405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to csv\n",
    "num_tweets_df.toPandas().to_csv('output/twitter/num_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd49970d",
   "metadata": {},
   "source": [
    "## 3. Find all the persons mentioned on tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddb7bc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+---------+--------------------+------------------+--------------------+\n",
      "|      country|                id|    place|                text|              user|     users_mentioned|\n",
      "+-------------+------------------+---------+--------------------+------------------+--------------------+\n",
      "|        India|572692378957430785|   Orissa|@always_nidhi @Yo...|   Srkian_nishu :)|[always_nidhi, Yo...|\n",
      "|United States|572575240615796737|Manhattan|@OnlyDancers Bell...|TagineDiningGlobal|       [OnlyDancers]|\n",
      "|United States|572575243883036672|Claremont|1/ \"Without the a...|       Daniel Beer|                  []|\n",
      "|United States|572575252020109313|   Vienna|idk why people ha...|  someone actually|                  []|\n",
      "|United States|572575274539356160|   Boston|Taste of Iceland!...|    BostonAttitude|    [IcelandNatural]|\n",
      "+-------------+------------------+---------+--------------------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType\n",
    "\n",
    "def generate_mentioned_user_list(text):\n",
    "    return [item.lstrip('@') for item in text.split(' ') if item.startswith('@')]\n",
    "\n",
    "\n",
    "twitter_df_with_mentioned = twitter_df.withColumn('users_mentioned', udf(lambda text: generate_mentioned_user_list(text), ArrayType(StringType()))(col('text')))\n",
    "twitter_df_with_mentioned.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e495c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to csv\n",
    "twitter_df_with_mentioned.toPandas().to_csv('output/twitter/mentioned_users.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff31da",
   "metadata": {},
   "source": [
    "## 4. Count how many times each person is mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c20c8666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|users_mentioned|count|\n",
      "+---------------+-----+\n",
      "|DjRockyUg      |1    |\n",
      "|TrillHD        |1    |\n",
      "|TimmysWell     |1    |\n",
      "|brookie_baldwin|1    |\n",
      "|TTTorrez       |2    |\n",
      "|boytoyjesse    |1    |\n",
      "|misstoriblack  |1    |\n",
      "|globalstatmusic|1    |\n",
      "|_fuckgio       |1    |\n",
      "|PedroIvoChianca|1    |\n",
      "|Cpiepz         |1    |\n",
      "|avachristy3    |1    |\n",
      "|lostbayouramble|1    |\n",
      "|bellahadid     |1    |\n",
      "|sawano_nZk's   |1    |\n",
      "|marIboros      |1    |\n",
      "|kochamjacksona |1    |\n",
      "|WIOD           |2    |\n",
      "|ShaelynCherie  |2    |\n",
      "|KevinAnex      |1    |\n",
      "+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "# explode flattens the previous step array into a column\n",
    "mentioned_only_df = twitter_df_with_mentioned.select(explode(col('users_mentioned')).alias('users_mentioned'))\n",
    "\n",
    "# the users_mentioned list contains '' also, so exclude that\n",
    "mentioned_only_df = mentioned_only_df.filter(col('users_mentioned') != '')\n",
    "\n",
    "# count of mentioned users\n",
    "mentioned_only_df.groupBy('users_mentioned').count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c93c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to csv\n",
    "mentioned_only_df.groupBy('users_mentioned').count().toPandas().to_csv('output/twitter/mentioned_users_count.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c58aaf2",
   "metadata": {},
   "source": [
    "## 5. Find the 10 most mentioned persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8a8f17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|users_mentioned|count|\n",
      "+---------------+-----+\n",
      "|    ShawnMendes|  189|\n",
      "|  HIITMANonDECK|  100|\n",
      "|officialdjjuice|   59|\n",
      "|         MAEJOR|   45|\n",
      "|    MR_JAYJONES|   41|\n",
      "|       MeekMill|   35|\n",
      "|MadisonElleBeer|   30|\n",
      "|              ‚Ä¶|   28|\n",
      "|     DjLordDash|   27|\n",
      "|     NICKIMINAJ|   25|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_mentioned_df = mentioned_only_df\\\n",
    "    .groupBy('users_mentioned')\\\n",
    "    .count().orderBy(col('count').desc())\\\n",
    "    .limit(10)\n",
    "\n",
    "top_mentioned_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6912890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to csv\n",
    "top_mentioned_df.toPandas().to_csv('output/twitter/top_mentioned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fd20cc",
   "metadata": {},
   "source": [
    "## 6. Find all the hashtags mentioned on a tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b171c389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+---------+--------------------+------------------+--------+\n",
      "|      country|                id|    place|                text|              user|hashtags|\n",
      "+-------------+------------------+---------+--------------------+------------------+--------+\n",
      "|        India|572692378957430785|   Orissa|@always_nidhi @Yo...|   Srkian_nishu :)|      []|\n",
      "|United States|572575240615796737|Manhattan|@OnlyDancers Bell...|TagineDiningGlobal|      []|\n",
      "|United States|572575243883036672|Claremont|1/ \"Without the a...|       Daniel Beer|      []|\n",
      "|United States|572575252020109313|   Vienna|idk why people ha...|  someone actually|      []|\n",
      "|United States|572575274539356160|   Boston|Taste of Iceland!...|    BostonAttitude|      []|\n",
      "+-------------+------------------+---------+--------------------+------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_hashtags_list(text):\n",
    "    return [item for item in text.split(' ') if item.startswith('#')]\n",
    "\n",
    "twitter_df_with_hashtags = twitter_df.withColumn('hashtags', udf(lambda text: generate_hashtags_list(text), ArrayType(StringType()))(col('text')))\n",
    "twitter_df_with_hashtags.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "898ec530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to csv\n",
    "twitter_df_with_hashtags.toPandas().to_csv('output/twitter/hashtags.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b31efab",
   "metadata": {},
   "source": [
    "## 7. Count how many times each hashtag is mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "afe1c550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            hashtags|count|\n",
      "+--------------------+-----+\n",
      "|               #2NE1|    3|\n",
      "|         #musicLover|    1|\n",
      "|           #IBMCloud|    2|\n",
      "|#flexrecordingstudio|    1|\n",
      "|            #Hottest|    1|\n",
      "|        #VanessaBorn|    1|\n",
      "|        #happychappy|    1|\n",
      "|          #yyjevents|    1|\n",
      "|      #LittleLionMan|    1|\n",
      "|           #MBAMBADU|    7|\n",
      "|     #misheardlyrics|    1|\n",
      "|              #Indie|    2|\n",
      "|             #family|    1|\n",
      "|          #beautiful|    2|\n",
      "|             #Waiter|    1|\n",
      "|             #friend|    1|\n",
      "|    #recuseimita√ßoes|    1|\n",
      "|             #airbnb|    1|\n",
      "|              #B√òRNS|    1|\n",
      "|         #ChickCorea|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashtags_only_df = twitter_df_with_hashtags.select(explode(col('hashtags')).alias('hashtags')).filter(col('hashtags') != '')\n",
    "\n",
    "hashtags_only_df\\\n",
    "    .groupBy('hashtags')\\\n",
    "    .count()\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dfc33b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to csv\n",
    "hashtags_only_df.groupBy('hashtags').count().toPandas().to_csv('output/twitter/hashtag_count.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e00416",
   "metadata": {},
   "source": [
    "## 8. Find the 10 most popular Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57528508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|           hashtags|count|\n",
      "+-------------------+-----+\n",
      "|               #DME|  253|\n",
      "|          #ROADBOYZ|  251|\n",
      "|             #music|  236|\n",
      "|             #Paris|  144|\n",
      "|#QuissyUpSoonüî•üî•üíØ|  129|\n",
      "|      #QuissyUpSoon|  120|\n",
      "| #Trippythursdaymia|  100|\n",
      "|             #Music|   84|\n",
      "|    #MaejorMeAndYou|   44|\n",
      "|              #IGGL|   41|\n",
      "+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_hashtags_df = hashtags_only_df\\\n",
    "    .groupBy('hashtags')\\\n",
    "    .count()\\\n",
    "    .orderBy(col('count').desc())\\\n",
    "    .limit(10)\n",
    "\n",
    "top_hashtags_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07833675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to csv\n",
    "top_hashtags_df.toPandas().to_csv('output/twitter/top_hashtags.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beb05a8",
   "metadata": {},
   "source": [
    "## 9. Find the top 5 countries which tweet the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77ba8e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+\n",
      "|       country|num_tweets|\n",
      "+--------------+----------+\n",
      "| United States|      4841|\n",
      "|        France|       737|\n",
      "|     Indonesia|       370|\n",
      "|United Kingdom|       365|\n",
      "|        Brasil|       256|\n",
      "+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_countries_df = twitter_df\\\n",
    "    .groupBy('country')\\\n",
    "    .count()\\\n",
    "    .withColumnRenamed('count', 'num_tweets')\\\n",
    "    .orderBy(col('num_tweets').desc())\\\n",
    "    .limit(5)\n",
    "\n",
    "top_countries_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8f1a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to csv\n",
    "top_countries_df.toPandas().to_csv('output/twitter/top_countries.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
